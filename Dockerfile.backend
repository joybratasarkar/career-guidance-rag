# Backend Dockerfile for FastAPI - Optimized for Render 512MB
FROM python:3.11-slim

# Memory optimization environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV MALLOC_TRIM_THRESHOLD_=100000
ENV TORCH_HOME=/tmp/torch
ENV TRANSFORMERS_CACHE=/tmp/transformers
ENV HF_HOME=/tmp/huggingface

# Set working directory
WORKDIR /app

# Install minimal system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Copy requirements first for better caching
COPY requirements-backend.txt requirements.txt

# Install dependencies in stages to reduce peak memory
RUN pip install --no-cache-dir --upgrade pip wheel && \
    pip install --no-cache-dir fastapi uvicorn motor redis hiredis python-multipart && \
    pip install --no-cache-dir torch --index-url https://download.pytorch.org/whl/cpu && \
    pip install --no-cache-dir sentence-transformers==5.0.0 && \
    pip install --no-cache-dir langchain-community langchain-google-vertexai langgraph && \
    rm -rf /root/.cache/pip /tmp/pip-* && \
    python -c "import gc; gc.collect()"

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Copy optimized startup script
COPY start_optimized.py .

# Command to run the optimized FastAPI backend
CMD ["python", "start_optimized.py"]